{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "\n",
    "data_path = os.path.expandvars('C:/Users/$USERNAME/Desktop/data/07_deep_learning/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1: Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class GenData(Sequence):\n",
    "    def __init__(self, path, split='train', batch_size=32, fraction=5):\n",
    "        self.split = split\n",
    "        self.path = os.path.join(path, split, 'output')\n",
    "        self.batch_size = batch_size\n",
    "        self.fraction = fraction\n",
    "\n",
    "        # TODO: lists containing data\n",
    "        self.x = [] # features: zero crossing, mfccs, ...\n",
    "        self.y = [] # speech activity: 0 / 1\n",
    "\n",
    "        # TODO: collect file names under *self.path*\n",
    "        self.files = ...\n",
    "\n",
    "        # only select a *fraction* of the file names to limit amount of \n",
    "        # training data\n",
    "        self.files = self.files[1 : int(len(self.files) / self.fraction)]\n",
    "\n",
    "        for file in tqdm(self.files):\n",
    "            # TODO: load file & save contents in *self.x* & *self.y*\n",
    "            pass\n",
    "\n",
    "        # Random order indices\n",
    "        self.idx = np.random.permutation(range(len(self.x)))\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        # get random indices of current batch\n",
    "        idx_batch = self.idx[item*self.batch_size : (item+1)*self.batch_size]\n",
    "\n",
    "        # TODO: get data for current batch from *self.x* / *self.y*\n",
    "        x_batch = ...\n",
    "        y_batch = ...\n",
    "\n",
    "        # TODO: find minimum length of data for current batch\n",
    "        minlen = ...\n",
    "\n",
    "        # TODO: stack data for current batch to tensors of proper size\n",
    "        x_tensor = ...\n",
    "        y_tensor = ...\n",
    "\n",
    "        return x_tensor, y_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.floor(len(self.x) / self.batch_size)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.split == 'train':\n",
    "            # reshuffle random order indices\n",
    "            self.idx = np.random.permutation(range(len(self.x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate one generator for training, validation and test data\n",
    "\n",
    "train_data = GenData(data_path, split='train', batch_size=32)\n",
    "val_data = GenData(data_path, split='val', batch_size=32)\n",
    "test_data = GenData(data_path, split='test', batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# draw one batch from the training generator\n",
    "x_train_0, y_train_0 = train_data[1]\n",
    "print(x_train_0.shape)\n",
    "print(y_train_0.shape)\n",
    "\n",
    "# check length of training generator\n",
    "print(len(train_data))\n",
    "\n",
    "# check if we can iterate whole generator\n",
    "for x, y in train_data:\n",
    "    pass\n",
    "\n",
    "# plot targets for 1st sentence of a batch\n",
    "plt.plot(y[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2: Feedforward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, Activation\n",
    "from tensorflow.keras.metrics import BinaryAccuracy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.losses import ... # TODO: which loss should be used?\n",
    "\n",
    "def build_feedforward_model(num_neurons=128, num_blocks=2, dropout_rate=0.15, learning_rate=1E-4):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # TODO: use ALL input arguments!\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for 1 epochs ...\n",
    "model_ff = build_feedforward_model()\n",
    "history_ff = model_ff.fit(train_data, validation_data=val_data, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_data):\n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "evaluate(model_ff, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. First Real Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ... and with 15 more epochs\n",
    "model_ff = build_feedforward_model()\n",
    "history_ff = model_ff.fit(train_data, validation_data=val_data, epochs=14)\n",
    "evaluate(model_ff, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 5: A Recurrent Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "def build_lstm_model(num_neurons=32, num_blocks=2, learning_rate=1E-4):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # TODO: construct & compile model\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# test with 1 epoch ...\n",
    "model_lstm = build_lstm_model()\n",
    "history_lstm = model_lstm.fit(train_data, validation_data=val_data, epochs=1)\n",
    "evaluate(model_lstm, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... and with 15\n",
    "model_lstm = build_lstm_model()\n",
    "history_lstm = model_lstm.fit(train_data, validation_data=val_data, epochs=15)\n",
    "evaluate(model_lstm, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 6: Different Learning Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "learning_rates = [1E-4, 1E-3, 1E-2]\n",
    "histories = []\n",
    "\n",
    "# TODO: build and train models for different learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compare loss over epoch for different learning rates"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b576286d6e9b828d15dac98996e9baf69d8551f34156323e33f5830a513e0082"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
