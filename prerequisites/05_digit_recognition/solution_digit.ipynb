{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_path = os.path.expandvars('C:/Users/$USERNAME/Desktop/data/05_digit_recognition/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 Data Acquisition\n",
    "* Load the training data for the digits `['four', 'five', 'six', 'seven']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import lib_digit as lib\n",
    "\n",
    "lib.rel_thresh = 0.5\n",
    "lib.min_length = 0.25 # 250ms\n",
    "lib.frames_select = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Select one instance (dictionary) from the training set and display the dimensions of all contained features by iterating over the keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a FeatureSelector object and use it to generate a matrix mel_train where one row corresponds to the flattened log mel spectrum of one training instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How many features does one instance have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use the same object to generate a matrix mel_test containing the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 Logistic Regression \n",
    "* Create a logistic regression object with C=1000 and max_iter=1000.\n",
    "* Train the model with the extracted training data (mel spectra). Probably you will receive a warning that the training did not converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Exercise 3 Model Evaluation\n",
    "* Compute all predicted posterior probabilities on the test set and then plot $p(\\texttt{’four’}|\\mathbf{x})$ for all x in the test set.\n",
    "* In the same diagram add a line with the true posterior probability p(’four’|x).\n",
    "This probability is 1 if it is known that an instance is a 'four' and zero otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* In another diagram, generate the same curves for the training set. Is the training data linearly separable?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Visualize the normalized confusion matrix for the test set. Which false classification happens most often?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Create a Pipeline with a `FeatureSelector` and a `LogisticRegression` object. Let\n",
    "the `FeatureSelector` select only the log-mel-spectra and allow 1000 iterations\n",
    "for the `LogisticRegression` object. Set the `Pipeline`’s `verbose` attribute to `True`\n",
    "in order to see the fitting time.\n",
    "* Fit the `Pipeline` with the training data and compute the accuracy score on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Then add a `StandardScaler` to the `Pipeline` and compare accuracy and fitting time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Repeat these steps but let the FeatureSelector select all cepstral coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Denote accuracy and fitting times in the following table. How do scaler and the reduced number of features impact the pipeline?\n",
    "\n",
    "| Feature \t| With Scaler \t| Fitting Time \t| Accuracy \t|\n",
    "|---------\t|-------------\t|--------------\t|----------\t|\n",
    "| log_mel \t| no          \t| ...          \t| ...      \t|\n",
    "| log_mel \t| yes         \t| ...           | ...      \t|\n",
    "| mfcc    \t| no          \t| ...           | ...      \t|\n",
    "| mfcc    \t| yes         \t| ...           | ...      \t|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Exercise 5: Grid Search\n",
    "\n",
    "* Create a Pipeline with cepstral coefficiens as input features, standard scaling\n",
    "and logistic regression with a maximum of 1000 iterations.\n",
    "\n",
    "* Define a parameter grid where you vary the regularization parameter `C` of the\n",
    "estimator in an exponential range from $10^{−5}$ to $10^5$ and the number of selected\n",
    "cepstral coefficients between 2 and 30 in steps in 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Exercise 6: Dimensionality Reduction\n",
    "* Create a `Pipeline` with a `FeatureSelector` and a `KNeighborsClassifier`. The\n",
    "`FeatureSelector` should select the mel-frequency spectrum. Fit the `Pipeline`\n",
    "and display the accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import  KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Now create a second `Pipeline`, where a `NeighborhoodComponentAnalysis` is added\n",
    "before the classifier, and provide a memory argument, so that the `Pipeline` is able to cache fitted estimators.\n",
    "* Create a parameter grid where you vary `nca__n_components` (4-5 values) and\n",
    "`knn__n_neighbors` (5-8 values).\n",
    "* Create a `GridSearchCV` with the Pipeline, the parameter grid and the argument\n",
    "`verbose=3.`\n",
    "* Fit the grid search and investigate the fitting time for the parameter configurations.\n",
    "How can you observe the effect of caching?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NeighborhoodComponentsAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Exercise 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Exercise 8\n",
    "* Your turn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}